================================================================
   Title : SystemC-based Simulator
   Author: Guang Yang
   Date  : Sep. 13, 2004
   $Id: README.txt,v 1.2 2004/10/09 19:45:11 guyang Exp $
================================================================
1. Introduction
2. SystemC Execution Model
3. Simulate metamodel with SystemC
   3.1. Execution Model
   3.2. Modeling Metamodel Objects
   3.3. Modeling Metamodel Types
   3.4. Enforcing LTL Constraints
4. Simulation Optimization 
   4.1. Medium Centric Simulation
   4.2. Named Event Reduction
   4.3. Interleaving Concurrent Specific Optimization
   4.4. Efficient Synchronization Constraints Resolution
   4.5. Call Graph Recording and Reduction
5. User's Guide
================================================================



================================================================
1. Introduction
================================================================
SystemC-based simulator is currently the main validation tool
used in Metropolis infrastructure. It starts with the abstract 
syntax tree (AST) generated by the Metropolis compiler frontend. 
After performing all applicable optimization techniques described
in section 4, it generates SystemC code for the metamodel 
description while maintaining the metamodel semantics. 
During code generation, it also produces a make file systemc_sim.mk
for compilation purpose. Once the SystemC code is compiled and
linked with the simulation libararies provided by both SystemC
and this particular backend tool, the executable will show the 
metamodel simulation result.

================================================================
2. SystemC Execution Model
================================================================
SystemC is based on C++. There are a number of libraries which 
support SystemC semantics. Basiclly, SystemC program is a single 
thread program. But, SystemC can be used to model concurrent
modules, such as in a hardware system. The way SystemC deals with 
this concurrency is to use the interleaving concurrent semantics,
i.e. transfer execution from one module to another, thus make 
different modules run sequentially. Because SystemC employs 
non-preemptive model, execution transfer can occur only when 
the current executing module voluntarily stops by executing wait(). 
If there is not such wait() statements in a module, and once it 
gets started, it will possess the CPU forever. After one module 
gives out CPU, SystemC scheduler will choose another ready-to-run 
module and let it go. The order of the ready-to-run modules 
chosen is nondeterministic.

In SystemC, there are two kinds of synchronization mechanisms. 
One is event, the other is time. 
- Event is often used between an event notifier and an event 
  receiver. When an event notifier notifies an event, it can 
  point out the time this event becomes effective, for instance 
  one nano-second. It is easy to understand this one-to-one 
  relation, so is the one-to-multiple relation. But how does 
  multiple-to-one event synchronization work? This depends on 
  one important feature of event, i.e. when the same event is 
  notified by multiple notifiers and they all become effective 
  at exactly the same time(delta cycle, will be addressed below), 
  these multiple events are reduced to only one. Thus, if a receiver 
  is waiting for this event, instead of being triggered multiple 
  times, it will be triggered only once.

- Similar with VHDL and Verilog, SystemC supports real time and 
  delta cycle. Real time can be used to model system response 
  delay, synchronize different modules, etc. At any given time 
  point, there could be infinite delta cycles. Within a single 
  delta cycle, SystemC scheduler will make each ready module run. 
  One running module may incur other modules ready to run by 
  notifing an event immediately. When there are no pending events 
  in current delta cycle, simulation will go further to the next 
  delta cycle or (if no pending events in the next delta cycle) 
  to next time point.

================================================================
3. Simulate metamodel with SystemC
================================================================
3.1. Execution Model
3.1.1. Simulation Manager and Scoreboard
After translating Metamodel into SystemC, for each Metamodel 
object, there could be found one corresponding object in SystemC. 
(These correspondeces will be addressed below.) Besides all the 
objects defined in Metamodel file, there are two additional 
objects in SystemC to assist maintaining Metamodel semantics in 
SystemC. They are simulation manager and scoreboard.

- simulation manager
  Simulation manager is an actively running module, which is in 
  charge of the execution and synchronization among all other 
  objects. Simulation manager and all other objects correponding
  to metamodel processes run alternately. 

- scoreboard
  For each process, there is one dedicated ProgramCounter 
  associated with it. ProgramCounter is the most important data 
  structure in the SystemC based simulator, which consists abundant 
  information such as the execution history, current status and
  possible future movements.

3.1.2. Two Phases in Simulation 
The entire simulation procedure can be divided into 2 phases: 
initializtion and simulation.

During initialization phase, all objects (passive and active) are 
instanciated; all connections between objects are set up; all 
processes register themselves to scoreboard; information of 
(port name, medium) pairs are stored in corresponding objects that 
defines that port and all synchronization information are stored
in the scoreboard.

After initialization, a SystemC command sc_start() is called 
to start simulation. Then, the execution is transfered between 
processes and simulation manager, therefore the simulation proceeds.

The following steps explain the execution transfer in detail. 
The number in each step corresponds to DeltaCyle in simulation.

1. After simulation starts, all processes wait at the very beginning. 
Manager also waits for one DeltaCycle. By doing this, it is 
guaranteed that ALL processes are initialized and ready to run. 

2. Manager invokes all processes by notifying an event, then wait.

3. All processes are awaken by manager, then start their own programs. 
Till they hit an await, label, block or interface function calls, 
they stop and invoke manager again to inquire an execution scheduling. 
It is possible that a number of processes are running concurrently. 
If so, the multiple-to-one synchronization model of events applies 
here. The execution of await is different from that of block, label 
or interface function call in that it makes a unique condition 
evaluation request to manager. While for others, they just inquire 
scheduling state from manager. In other words, delta cycle 3 and 4 
are eliminated for block, label or interface function call. The 
execution transfers from manager in delta cycle 2 to process in 
delta cycle 5 directly.

4. Manager receives the condition evaluation request from processes. 
It then invokes those processes which make these requests, while all 
other processes keep waiting.

5. Those processes, which need to evaluate conditions for awaits, 
get conditions for all critical sections. Since all condition evaluation 
in await statements do not have side effects, meaning, they do not 
change any state variables but evaluate them only. The execution order 
of these processes does not matter. Then execution goes back to manager 
again.

6. At this point, all processes have their necessary information ready 
for manager to decide which ones can run. These information is in fact 
stored in scoreboard. Because some processes might make requests in 
the previous request-manage cycle, and they are not scheduled to go by 
the manager. Thus, they are still waiting at block, label or interface 
function calls. To let them join in this round of decision making 
cycle, manager calls function preSet(), which enables those requests 
again. For those events which have quantity annotation requests, if they
are not granted in the previous cycle, the quantity annotation also 
need to be rerun in order to reflect state changes of the quantity 
requests. Then, manager calls the resolution functions defined in 
scheduling netlists (if any) and a series of functions to decide if 
each process could go or not.

7. Processes receiving invoke events from manager will resume 
execution. 

3.2. Modeling Metamodel Objects
3.2.1. Port and Interfaces
Since SystemC has the concepts of port and interface already, 
it is straightforward to transform them from Metamodel to SystemC. 
The only difference is the syntax.

'port interfacName portName;' in metamodel becomes
'sc_port<interfaceName> portName;' in SystemC.

During simulation, since an interface function may be blocked 
by a await statement, whenever an interface function is called, 
at the very beginning of that interface function,
new states will be set, which includes function type, interface 
name, SchedState, etc.;
then, execution is transfered to manager, then wait to be invoked.

Manager will check if this interface function can run or not. 
More precisely, check if any other processes prevent it from running 
because of having it in SetList in an await statement. If the 
interface function is decided to RUN, manager will invoke it; 
otherwise, nothing will happen, and this interface function will be 
checked next time manager runs (invoked by other processes).

3.2.2. Process
In Metamodel, processes are active objects, meaning, they run on 
their own threads. In SystemC, there is one corresponding object,
i.e. sc_module. So, process can be implemented by extending sc_module.
Each process has one dedicated ProgramCounter. It is used to record 
program execution and for manager to make execution and scheduling 
decisions. 

3.2.3. Medium
Medium is a passively running object. It can run only when being 
called. Therefore, medium does not have its own ProgramCounter. 
Instead, its execution is reflected in its caller process's 
ProgramCounter. Like process, medium also has a counterpart in 
SystemC, i.e. sc_channel. Process and medium are quite similar 
except that process inherits sc_module, while medium inherits 
sc_channel.

3.2.4. StateMedium
Statemedium is a kind of medium. It is a bridge between a process 
and for example a quantity. 

3.2.5. Quantity
Quantities are special objects usually existing in scheduling 
netlists. It will resolve the quantities and therefore aid to 
make some execution decisions. It can run only in manager's thread. 
In this sense, quantities behave just like medium does, which can 
run only in processes' threads. So, a quantity inherits sc_channel. 

3.2.6. Netlist
In Metamodel, netlist is a container of objects. It is like module
in Verilog, which encapsulates multiple objects in a single box. 
Netlist is also an essential building block for refinement. 
A process or medium could be refined by a netlist. This way, design 
reuse can be achieved. The third usage of netlists is that they
can classify the objects into scheduled and scheduling netlists.

Since netlists do not have active threads, they are modeled with
sc_channel in SystemC.

3.3. Modeling Metamodel Types
Since SystemC is based on C++, and C++ perfectly supports all 
data types and operations used in Metamodel, such as int, float, 
boolean, byte, template, etc. Then, the translation from Metamodel 
to SystemC is quite simple. The only thing that need
s more attention is the slightly different syntax for some of them,
such as changing boolean to bool, changing byte to char.

Another big convenience in metamodel is templates. Though this
is not easy to handle in frontend and elaboration, they can be
naturally handled in SystemC simulator, because templates are
present in standard C++ and have the same formats in both C++
and metamodel.

3.4. Enforcing LTL Constraints
In metamodel language, users can use both imperative statements
and formal constraints to describe a system. Formal constraints
include Linear Temporal Logic (LTL) and Logic of Constraints
(LOC). The latter can be used to check runtime properties, but
they would influence the behavior of the imperative statements.
LTL is more powerful in that it could be part of the description
and restrain the system behavior.

This ability is especially meaningful in today's electronic 
system design, where there is wide consensus that increased design 
productivity requires raising the level of abstraction. 
However the popular modeling languages, such as C, C++ and SystemC,
are still not abstract enough in the sense that many details 
have to be given in order to implement certain behaviors or 
properties. 

On the other hand, if we see a system as a "function" that satisfies 
a set of properties, simply declaring them, rather than implementing
them, could save significant design efforts in system modeling, e.g.
describe a system by imperative specification and declarative
LTL constraints in Metropolis.

Having specified a system with the mixture of imperative code and
declarative LTL constraints, the simulator has to exhibit the behavior 
that can be generated by the imperative code and satisfies the LTL 
constraints. However, it is difficult to deal with LTL constraints 
in simulation, because they specify only what the behavior should 
be not how to realize it. If we can transform the declarative 
constraints into operational ones, then simulator can handle them 
more easily.

Towards this direction, using Buchi Automaton (BA) to represent 
LTL constraints becomes an obvious candidate. Suppose BA is 
already constructed for LTL constraints. The simulator needs to 
keep track of two sets of states, those of all metamodel processes 
and those of the BA. 
Simulation starts from the initial states of the system and BA.
Whenever a scheduling decision needs to be made, the simulator 
checks BA to eliminate illegal transitions. In remaining legal 
transitions, compatible sets are chosen due to system state and 
metamodel semantics. Then, check BA again to select the best 
choice. 

Note that there are limitations to the above simulation strategy.
Better scheduling heuristics are under development.
 
================================================================
4. Simulation Optimization 
================================================================
The simulation algorithm described in the third section is
straightforward. Basically, it lets each process stop at blocks,
labels, interface functions and await statements. Then, wait for
the decisions from the simulation manager. However, not every 
above stopping point is necessary. The excessive stopping slows
down the simulation speed. In order to improve the simulation
performance, the following optimization techniques are applied.

(For details about the optimization techniques, please refer
to the paper 
G. Yang, A. Sangiovanni-Vincentelli, Y. Watanabe and F. Balarin,
"Separation of Concerns: Overhead in Modeling and Efficient
Simulation Techniques", EMSOFT 2004, Pisa, Italy. )

4.1. Medium Centric Simulation
The basic idea of this technique is that, since communication media
are the critical region of mutual exclusion, we can store all the 
interface usage information there and let all processes update the
information during interface function calls or await's.
When interface function calls enter the functions, they
need to register to the media that their interfaces are being
used; after they finish, they retract the registration. For
awaits, when entering a critical section, they need to raise a 
flag indicating that all interfaces in the corresponding SetList
are prohibited; after they finish, they put the flag down. 
Having these interface status information, a process has to 
compare its need of using an interface with the status of the 
medium implementing it only once. Thus, the time complexity is 
reduced from quadratic to linear in the number of the processes.

4.2. Named Event Reduction
A named event is an event that can be referred to either in
an await statement, or in declarative coordination constraints 
such as simultaneity constraints. For instance, the beginning 
of an interface function call is a named event because it can 
be referred to in an await statement. 

Note that although in general named events should be treated in 
a special and potentially costly way, under some circumstances they 
can be safely ignored without violating the execution semantics.

Named event reduction is a technique to recognize such events.
One such case is the events for an interface function implemented 
by a medium that do not appear in any of the TestList and SetList
in the processes connected to it or inside the medium itself.
In this case, these events are no longer dealt as named events, 
thus there is no simulation overhead for the additional checks.
Note that this analysis depends not only on the sequential program
associated with the medium, but also on how the medium is
instantiated in the current design, i.e. the connections with
other objects and constraints specified with the design.
Therefore, we make this analysis statically after the construction
of all the networks of the processes, and keep track of only the
named events that are indeed referred to in the design
description.

4.3. Interleaving Concurrent Specific Optimization
When the target simulation language uses interleaving concurrency
semantics, such as SystemC, specific optimization techniques can
be applied. Under this execution semantics, a process continues
to run until it voluntarily lets others execute, assuming that 
this is the only process that is currently running.  The release
points are typically statements which block the process until 
certain conditions become true. This single-running-process feature
allows to simplify the checking of mutual exclusion constraints 
in some cases, and possibly to eliminate simulation overhead 
associated with some await statements.

4.4. Efficient Synchronization Constraints Resolution
In metamodel descriptions, ltl synch constraints could be used
to relate the execution of two events. This mechanism is often
used to achieve function and architecture mapping.

In simulating the design description, we need to ensure the 
satisfaction of the constraints. In general, there is no 
limitation on the number of events in behavior and architecture 
that are related by mapping. During run time, quickly identifying
events that need to be synchronized with other events, and deciding
whether those events are enabled or not become a performance 
critical task. In a straightforward implementation, one needs 
to check all the simultaneity constraints every time an event 
becomes enabled, resulting in a number of checks that grows 
quadratically with the number of events.

We manage this complexity by using a combination of static and
dynamic techniques.
In the static phase, we parse all the simultaneity constraints
specified by the keyword synch. By definition, these constraints 
form a set of equivalence classes over the specified
events, so that two events are in the same class if they are
constrained by this keyword. We compute this set statically, 
and annotate each of the events with the identifier of the 
equivalence class it belongs to.

In the dynamic phase (during simulation), we use a counter
associated with each equivalence class, which keeps track of the 
number of enabled events in the equivalence class. 
Note that the an enabled event does not mean that the event will 
be issued, because various coordination constraints may be specified 
at the event. When we check the simultaneity constraints, we first 
compare the counter with the cardinality of the equivalence class. 
If they are not equal, at least one of the events is not enabled, 
which allows us to disable quickly all the events in this class. 
This mechanism reduces the number of events for which we need to
check coordination constraints,resulting in a very significant 
reduction of simulation time.

4.5. Call Graph Recording and Reduction
The simulation manager resolves quantity annotation requests by
calling the resolve functions of all the quantity managers iteratively,
until they all agree on a set of annotations. To impose an order
on calls to quantity managers' resolve's, every network also
has a resolve function. The default behavior of this function is 
to call resolve functions of all the quantity managers defined 
at that level, and also of all the networks at the lower levels 
of hierarchy. This default behavior can be modified by the user. 
The simulation manager then calls only resolve of the top-level 
network. This simple scheme has a disadvantage of many function 
calls whose sole purpose is to traverse the network hierarchy. 
To improve simulation efficiency, the first time quantities are 
resolved, we record quantity managers called and their order in 
a list. After that, the quantity managers are called according 
to this list, eliminating unnecessary network hierarchy traversals.


================================================================
5. User's Guide
================================================================
5.1. Invoking SystemC backend
Metropolis design environment provides shell scripts to invoke
SystemC backend. The script command is 'systemc' or 
'metacomp -systemc'. They are exactly the same.
These two shell scripts take the following arguments:

  systemc [-top <netinit>] [-java <path>/java] [-javac <path>/javac]
          [-w] [-noic] [-mmdebug]
          [-classpath <classpath>]

-top <netinit>: specify the top level netlist. The name should
                be a fully qualified name of the netlist including
                all the package hierarchies from the top most package.
-java <path>/java: specify the location of Java virtual machine 
-javac <path>/javac: specify the location of Java compiler 
-w: Regenerate systemc code regardless the time stamps of mmm files
                and SystemC files. Without this argument, if the 
                SystemC files are newer than the mmm files, they
                will be ignored in code generation.
-noic: Do not perform interleaving concurrent specific optimization
-mmdebug: Support mmm level debugging in simulation
-classpath <classpath>: Specify where to find the top level packages

5.2. Simulation Executable
By default, systemc backend will generate a make file called
systemc_sim.mk. Using it, a run.x executable will be generated.
There are also several arguments that run.x can take. They are:

run.x   [-help]  [-r]  [-t]  [-ltl]  [-ic] [-noqa]
        [-dumpev]  [-d <0-4>  [-synchp]  [-ltlp]  [-m] ]
        -help           Show this message
        -r              Exhibit true (not pseudo) randomness during simulation
        -t              Report time statistics on simulation
        -ltl            Enforce LTL constraints during simulation
        -ic             Use interleaving concurrent feature in simulation
        -noqa           Do not annotate quantities during simulation
        -dumpev         Dump event vectors during simulation
        -d <0-4>        Show scoreboard for each step during simulation.
                        A larger number gives more detailed information.
          -synchp       Show only the processes present in synch.
          -ltlp         Show only the processes present in ltl constraints.
          -m            Show all media.


